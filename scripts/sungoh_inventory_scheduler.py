#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì„±ì˜¤ ì¬ê³ í˜„í™© ë°ì´í„° ìŠ¤ì¼€ì¤„ëŸ¬
ë§¤ì¼ ì‹¤í–‰ë˜ì–´ ì—‘ì…€ íŒŒì¼ì—ì„œ ì›”ê°„ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  CSVë¡œ ì €ì¥í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬
"""

import os
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
import logging
import sys
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('../logs/sungoh_scheduler.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class SungohInventoryScheduler:
    """ì„±ì˜¤ ì¬ê³ í˜„í™© ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤"""
    
    def __init__(self, output_base_dir="../extracted_data"):
        self.base_path = Path("/mnt/sungil/VOL1/ilro/ì¼ë¡œ ì¬ê³ ê´€ë¦¬")
        self.output_base_dir = output_base_dir
        self.month_names = {
            1: "1ì›”", 2: "2ì›”", 3: "3ì›”", 4: "4ì›”", 5: "5ì›”", 6: "6ì›”",
            7: "7ì›”", 8: "8ì›”", 9: "9ì›”", 10: "10ì›”", 11: "11ì›”", 12: "12ì›”"
        }
        self.target_sheets = ["í›„ê¸° ì›”ê°„", "1ë™ ì›”ê°„"]
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ì‘ì—… ì¢…ë¥˜)
        self.category_mapping = {
            'ì…ì‹': 1,
            'ì „ì…': 2, 
            'ì „ì¶œ': 3,
            'ì¶œí•˜': 4,
            'íì‚¬': 5,
            'ë„íƒœ': 6
        }
        
        # ëˆì‚¬ëª… ë§¤í•‘ (piggery_idë¡œ ì‚¬ìš©)
        self.piggery_mapping = {
            'í›„ê¸° ì›”ê°„': 'í›„ê¸°',
            '1ë™ ì›”ê°„': '1ë™'
        }
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self._ensure_output_directory()
    
    def _ensure_output_directory(self):
        """ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±"""
        if not os.path.exists(self.output_base_dir):
            os.makedirs(self.output_base_dir)
            logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {self.output_base_dir}")
    
    def get_target_date_info(self, target_date=None):
        """
        ëŒ€ìƒ ë‚ ì§œì˜ ì •ë³´ë¥¼ ë°˜í™˜ (ê¸°ë³¸ê°’: ì–´ì œ)
        
        Args:
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ. Noneì´ë©´ ì–´ì œ ë‚ ì§œ ì‚¬ìš©
            
        Returns:
            tuple: (year, month_name, target_date)
        """
        if target_date is None:
            target_date = datetime.now() - timedelta(days=1)
        
        year = target_date.year
        month_name = self.month_names[target_date.month]
        
        return year, month_name, target_date
    
    def generate_file_paths(self, target_date=None):
        """
        ì—‘ì…€ íŒŒì¼ì˜ ê°€ëŠ¥í•œ ê²½ë¡œë“¤ì„ ìƒì„±
        
        Args:
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            list: ê°€ëŠ¥í•œ íŒŒì¼ ê²½ë¡œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        year, month_name, _ = self.get_target_date_info(target_date)
        filename = f"ì„±ì˜¤ ì¬ê³ í˜„í™© {month_name}.xlsx"
        
        # ê°€ëŠ¥í•œ ê²½ë¡œë“¤
        paths = [
            self.base_path / filename,  # ê¸°ë³¸ ê²½ë¡œ
            self.base_path / str(year) / filename  # ë…„ë„ í´ë” ë‚´ ê²½ë¡œ
        ]
        
        return paths
    
    def find_excel_file(self, target_date=None):
        """
        ì—‘ì…€ íŒŒì¼ì„ ì°¾ì•„ì„œ ê²½ë¡œ ë°˜í™˜
        
        Args:
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            Path or None: ì°¾ì€ íŒŒì¼ì˜ ê²½ë¡œ, ì—†ìœ¼ë©´ None
        """
        year, month_name, date_info = self.get_target_date_info(target_date)
        possible_paths = self.generate_file_paths(target_date)
        
        logger.info(f"ë‚ ì§œ: {date_info.strftime('%Y-%m-%d')} ({year}ë…„ {month_name})")
        logger.info("ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤:")
        
        for path in possible_paths:
            logger.info(f"  - {path}")
            if path.exists():
                logger.info(f"âœ“ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {path}")
                return path
        
        logger.warning("í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    def read_excel_sheet(self, sheet_name, target_date=None):
        """
        íŠ¹ì • ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ ì½ì–´ì„œ pandas DataFrameìœ¼ë¡œ ë°˜í™˜
        
        Args:
            sheet_name (str): ì½ì„ ì‹œíŠ¸ëª…
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            pandas.DataFrame or None: ì½ì€ ë°ì´í„°, ì‹¤íŒ¨ì‹œ None
        """
        file_path = self.find_excel_file(target_date)
        
        if file_path is None:
            logger.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ '{sheet_name}' ì‹œíŠ¸ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            logger.info(f"ì‹œíŠ¸ '{sheet_name}' ì½ê¸° ì„±ê³µ: {df.shape[0]}í–‰ Ã— {df.shape[1]}ì—´")
            return df
            
        except Exception as e:
            logger.error(f"ì‹œíŠ¸ '{sheet_name}' ì½ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def filter_previous_day_data(self, df, target_date=None):
        """
        DataFrameì—ì„œ ì „ë‚  ë°ì´í„°ë§Œ í•„í„°ë§
        
        Args:
            df (pandas.DataFrame): ì „ì²´ ì›”ê°„ ë°ì´í„°
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ (ê¸°ë³¸: ì–´ì œ)
            
        Returns:
            pandas.DataFrame or None: ì „ë‚  ë°ì´í„°ë§Œ í¬í•¨ëœ DataFrame
        """
        if df is None or df.empty:
            return None
        
        try:
            # ëŒ€ìƒ ë‚ ì§œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            _, _, date_info = self.get_target_date_info(target_date)
            target_date_str = date_info.strftime("%Y-%m-%d")
            
            # í—¤ë” í–‰ë“¤ (ë‚ ì§œê°€ ì•„ë‹Œ ë©”íƒ€ ì •ë³´) ë³´ì¡´
            header_rows = []
            data_rows = []
            
            for idx, row in df.iterrows():
                first_col_value = str(row.iloc[0]).strip()
                
                # ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸ (YYYY-MM-DD ë˜ëŠ” YYYY-MM-DD HH:MM:SS)
                if first_col_value.startswith('202') and '-' in first_col_value:
                    # ì‹¤ì œ ë‚ ì§œ ë°ì´í„° í–‰
                    row_date = first_col_value.split(' ')[0]  # ì‹œê°„ ë¶€ë¶„ ì œê±°
                    if row_date == target_date_str:
                        data_rows.append(row)
                        logger.info(f"ì „ë‚  ë°ì´í„° ë°œê²¬: {row_date}")
                else:
                    # í—¤ë” í–‰ (ë‚ ì§œ, êµ¬ë¶„, ì»¬ëŸ¼ëª… ë“±)
                    header_rows.append(row)
            
            if not data_rows:
                logger.warning(f"ì „ë‚  ë°ì´í„°({target_date_str})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # í—¤ë” + ì „ë‚  ë°ì´í„°ë§Œ í¬í•¨ëœ ìƒˆ DataFrame ìƒì„±
            filtered_rows = header_rows + data_rows
            filtered_df = pd.DataFrame(filtered_rows).reset_index(drop=True)
            
            logger.info(f"ì „ë‚  ë°ì´í„° í•„í„°ë§ ì™„ë£Œ: {len(data_rows)}í–‰ì˜ ì‹¤ì œ ë°ì´í„°")
            return filtered_df
            
        except Exception as e:
            logger.error(f"ì „ë‚  ë°ì´í„° í•„í„°ë§ ì‹¤íŒ¨: {e}")
            return None
    
    def save_data_to_csv(self, df, sheet_name, target_date=None, daily_only=False):
        """
        DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            df (pandas.DataFrame): ì €ì¥í•  ë°ì´í„°
            sheet_name (str): ì‹œíŠ¸ëª… (íŒŒì¼ëª…ì— ì‚¬ìš©)
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            daily_only (bool): Trueì´ë©´ ì „ë‚  ë°ì´í„°ë§Œ ì €ì¥
            
        Returns:
            str or None: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ, ì‹¤íŒ¨ì‹œ None
        """
        if df is None:
            logger.error(f"ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {sheet_name}")
            return None
        
        try:
            # ì „ë‚  ë°ì´í„°ë§Œ í•„í„°ë§í• ì§€ ê²°ì •
            if daily_only:
                df = self.filter_previous_day_data(df, target_date)
                if df is None:
                    return None
            
            # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ë‚ ì§œ ê²°ì • (ì²˜ë¦¬í•œ ë°ì´í„°ì˜ ë‚ ì§œ)
            _, _, date_info = self.get_target_date_info(target_date)
            file_date = date_info.strftime("%Y%m%d")
            
            safe_sheet_name = sheet_name.replace(" ", "_").replace("ì›”ê°„", "monthly")
            
            # íŒŒì¼ëª…ì— daily êµ¬ë¶„ ì¶”ê°€
            file_suffix = "daily" if daily_only else "monthly"
            csv_filename = f"{self.output_base_dir}/sungoh_{safe_sheet_name}_{file_suffix}_{file_date}.csv"
            
            # CSV ì €ì¥
            df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
            logger.info(f"ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {csv_filename}")
            
            return csv_filename
            
        except Exception as e:
            logger.error(f"CSV ì €ì¥ ì‹¤íŒ¨ ({sheet_name}): {e}")
            return None
    
    def parse_csv_to_inventory_changes(self, csv_file_path, sheet_name, target_date=None):
        """
        CSV íŒŒì¼ì„ ì½ì–´ì„œ ì¬ê³  ë³€í™” JSON ë°°ì—´ë¡œ ë³€í™˜
        
        Args:
            csv_file_path (str): CSV íŒŒì¼ ê²½ë¡œ
            sheet_name (str): ì‹œíŠ¸ëª… (ëˆì‚¬ëª… ë§¤í•‘ìš©)
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            list: ì¬ê³  ë³€í™” ê¸°ë¡ JSON ë°°ì—´
        """
        try:
            df = pd.read_csv(csv_file_path, encoding='utf-8-sig')
            logger.info(f"CSV íŒŒì¼ ì½ê¸° ì„±ê³µ: {csv_file_path}")
            
            # ëŒ€ìƒ ë‚ ì§œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            _, _, date_info = self.get_target_date_info(target_date)
            created_at = date_info.strftime("%Y-%m-%dT09:00:00.000Z")  # ì˜¤ì „ 9ì‹œ ê³ ì •
            
            # ëˆì‚¬ëª… ì¶”ì¶œ
            piggery_name = self.piggery_mapping.get(sheet_name, sheet_name)
            
            # ë‚ ì§œ í¬ë§·íŒ… (í•œêµ­ì–´)
            date_korean = date_info.strftime("%Yë…„ %mì›” %dì¼")
            
            inventory_changes = []
            
            # ë°ì´í„° í–‰ ì°¾ê¸° (ë‚ ì§œë¡œ ì‹œì‘í•˜ëŠ” í–‰)
            data_row = None
            room_names = []
            
            for idx, row in df.iterrows():
                first_col = str(row.iloc[0]).strip()
                
                # ì‹¤ì œ ë°ì´í„° í–‰ ì°¾ê¸°
                if first_col.startswith('202') and '-' in first_col:
                    data_row = row
                    break
                
                # ë°© ì´ë¦„ ì •ë³´ ì¶”ì¶œ (êµ¬ë¶„ í–‰ì—ì„œ)
                if first_col == 'êµ¬ë¶„':
                    for col_idx, cell in enumerate(row):
                        cell_str = str(cell).strip()
                        if cell_str.endswith('ë°©') and cell_str != 'êµ¬ë¶„':
                            room_names.append(cell_str)
            
            if data_row is None:
                logger.warning("ë°ì´í„° í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # í—¤ë” ì •ë³´ì—ì„œ ì‘ì—… ì¢…ë¥˜ì™€ ë°© ì •ë³´ ë§¤í•‘
            header_row = None
            for idx, row in df.iterrows():
                if 'ì…ì‹' in str(row.values):
                    header_row = row
                    break
            
            if header_row is None:
                logger.warning("í—¤ë” í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ê° ë°©ë³„ë¡œ ì‘ì—… ë°ì´í„° ì¶”ì¶œ
            col_idx = 1  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ë‚ ì§œì´ë¯€ë¡œ ì œì™¸
            room_idx = 0
            
            while col_idx < len(data_row) and room_idx < len(room_names):
                room_name = room_names[room_idx]
                
                # ê° ë°©ì˜ 8ê°œ ì‘ì—… í•­ëª© (ì…ì‹, ì „ì…, ì „ì¶œ, ë„íƒœ, íì‚¬, ì¶œí•˜, ì˜¤ë¥˜, ì¬ê³ )
                room_data = {}
                work_types = ['ì…ì‹', 'ì „ì…', 'ì „ì¶œ', 'ë„íƒœ', 'íì‚¬', 'ì¶œí•˜', 'ì˜¤ë¥˜', 'ì¬ê³ ']
                
                # í•´ë‹¹ ë°©ì˜ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
                for i, work_type in enumerate(work_types):
                    if col_idx + i < len(data_row):
                        value = data_row.iloc[col_idx + i]
                        room_data[work_type] = value if pd.notna(value) else 0
                
                # ëˆêµ° ìƒì„± ì—¬ë¶€ íŒë‹¨ (ì…ì‹ ë‘ìˆ˜ì™€ í˜„ì¬ ì¬ê³ ê°€ ê°™ìœ¼ë©´ ìƒˆë¡œìš´ ëˆêµ°)
                ì…ì‹_ë‘ìˆ˜ = room_data.get('ì…ì‹', 0)
                í˜„ì¬_ì¬ê³  = room_data.get('ì¬ê³ ', 0)
                
                is_herd_created = False
                if (pd.notna(ì…ì‹_ë‘ìˆ˜) and pd.notna(í˜„ì¬_ì¬ê³ ) and 
                    str(ì…ì‹_ë‘ìˆ˜).replace('.', '').isdigit() and str(í˜„ì¬_ì¬ê³ ).replace('.', '').isdigit() and
                    float(ì…ì‹_ë‘ìˆ˜) > 0 and float(ì…ì‹_ë‘ìˆ˜) == float(í˜„ì¬_ì¬ê³ )):
                    is_herd_created = True
                    logger.info(f"{piggery_name} {room_name}: ëˆêµ° ìƒì„± ê°ì§€ (ì…ì‹:{ì…ì‹_ë‘ìˆ˜}, ì¬ê³ :{í˜„ì¬_ì¬ê³ })")
                
                # ê° ì‘ì—… íƒ€ì…ë³„ ì¬ê³  ë³€í™” ê¸°ë¡ ìƒì„±
                for work_type in ['ì…ì‹', 'ì „ì…', 'ì „ì¶œ', 'ë„íƒœ', 'íì‚¬', 'ì¶œí•˜']:
                    value = room_data.get(work_type, 0)
                    
                    # ê°’ì´ ìˆ«ìì´ê³  0ë³´ë‹¤ í° ê²½ìš°ë§Œ ì²˜ë¦¬
                    if pd.notna(value) and str(value).replace('.', '').isdigit() and float(value) > 0:
                        change_count = int(float(value))
                        
                        # ëˆêµ°ëª… ìƒì„±: "ë‚ ì§œ + ëˆë°©ëª… + ëˆêµ°"
                        herd_name = f"{date_korean} {room_name} ëˆêµ°"
                        
                        # JSON ê°ì²´ ìƒì„±
                        change_record = {
                            "category_id": self.category_mapping[work_type],
                            "change": change_count,
                            "created_at": created_at,
                            "piggery_id": piggery_name,
                            "herd_id": herd_name,
                            "is_created": is_herd_created and work_type == 'ì…ì‹'  # ì…ì‹ì´ë©´ì„œ ëˆêµ° ìƒì„±ì¸ ê²½ìš°ë§Œ True
                        }
                        
                        # arrival_room_id vs departure_room_id ê²°ì •
                        if work_type in ['ì…ì‹', 'ì „ì…']:
                            change_record["arrival_room_id"] = room_name
                        else:  # ì „ì¶œ, ì¶œí•˜, íì‚¬, ë„íƒœ
                            change_record["departure_room_id"] = room_name
                        
                        inventory_changes.append(change_record)
                        
                        # ëˆêµ° ìƒì„± ë¡œê·¸ ì¶”ê°€
                        created_text = " (ëˆêµ° ìƒì„±)" if change_record["is_created"] else ""
                        logger.info(f"{piggery_name} {room_name} {work_type}: {change_count}ë‘{created_text}")
                
                # ë‹¤ìŒ ë°©ìœ¼ë¡œ ì´ë™ (8ê°œ ì»¬ëŸ¼ ê±´ë„ˆë›°ê¸°: ì…ì‹,ì „ì…,ì „ì¶œ,ë„íƒœ,íì‚¬,ì¶œí•˜,ì˜¤ë¥˜,ì¬ê³ )
                col_idx += 8
                room_idx += 1
            
            logger.info(f"ì´ {len(inventory_changes)}ê°œì˜ ì¬ê³  ë³€í™” ê¸°ë¡ ìƒì„±")
            return inventory_changes
            
        except Exception as e:
            logger.error(f"CSV to JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
            return []
    
    def save_unified_inventory_changes_json(self, all_inventory_changes, target_date=None):
        """
        í†µí•© ì¬ê³  ë³€í™” JSON ë°°ì—´ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            all_inventory_changes (list): ëª¨ë“  ì¬ê³  ë³€í™” ê¸°ë¡ ë°°ì—´
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            
        Returns:
            str or None: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ, ì‹¤íŒ¨ì‹œ None
        """
        try:
            # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ë‚ ì§œ ê²°ì • (ì²˜ë¦¬í•œ ë°ì´í„°ì˜ ë‚ ì§œ)
            _, _, date_info = self.get_target_date_info(target_date)
            file_date = date_info.strftime("%Y%m%d")
            json_filename = f"{self.output_base_dir}/sungoh_inventory_changes_{file_date}.json"
            
            # JSON ì €ì¥ (í•œê¸€ ì§€ì›)
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(all_inventory_changes, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“„ í†µí•© JSON ì €ì¥ ì™„ë£Œ: {json_filename} ({len(all_inventory_changes)}ê±´)")
            return json_filename
            
        except Exception as e:
            logger.error(f"í†µí•© JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def extract_and_save_sheet(self, sheet_name, target_date=None, daily_only=False):
        """
        íŠ¹ì • ì‹œíŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  CSVë¡œ ì €ì¥
        
        Args:
            sheet_name (str): ì‹œíŠ¸ëª…
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            daily_only (bool): Trueì´ë©´ ì „ë‚  ë°ì´í„°ë§Œ ì €ì¥
            
        Returns:
            dict: ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
        """
        mode_text = "ì „ë‚  ë°ì´í„°" if daily_only else "ì›”ê°„ ë°ì´í„°"
        logger.info(f"ğŸ” '{sheet_name}' ì‹œíŠ¸ ì²˜ë¦¬ ì‹œì‘ ({mode_text})")
        
        # ë°ì´í„° ì½ê¸°
        df = self.read_excel_sheet(sheet_name, target_date)
        
        if df is None:
            return {
                'sheet_name': sheet_name,
                'success': False,
                'error': 'ë°ì´í„° ì½ê¸° ì‹¤íŒ¨',
                'file_path': None,
                'data_shape': None,
                'daily_only': daily_only
            }
        
        # CSV ì €ì¥ (daily_only ì˜µì…˜ ì „ë‹¬)
        csv_path = self.save_data_to_csv(df, sheet_name, target_date, daily_only)
        
        # JSON ë³€í™˜ (daily_onlyì¸ ê²½ìš°ì—ë§Œ)
        inventory_changes = []
        
        if csv_path and daily_only:
            inventory_changes = self.parse_csv_to_inventory_changes(csv_path, sheet_name, target_date)
        
        result = {
            'sheet_name': sheet_name,
            'success': csv_path is not None,
            'error': None if csv_path else 'CSV ì €ì¥ ì‹¤íŒ¨',
            'file_path': csv_path,
            'inventory_changes': inventory_changes,
            'inventory_changes_count': len(inventory_changes),
            'data_shape': df.shape,
            'daily_only': daily_only
        }
        
        if result['success']:
            logger.info(f"âœ… '{sheet_name}' ì²˜ë¦¬ ì™„ë£Œ: {mode_text}")
        else:
            logger.error(f"âŒ '{sheet_name}' ì²˜ë¦¬ ì‹¤íŒ¨")
        
        return result
    
    def run_daily_extraction(self, target_date=None, daily_only=False):
        """
        ì¼ì¼ ë°ì´í„° ì¶”ì¶œ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ í•¨ìˆ˜)
        
        Args:
            target_date (datetime, optional): ëŒ€ìƒ ë‚ ì§œ
            daily_only (bool): Trueì´ë©´ ì „ë‚  ë°ì´í„°ë§Œ ì¶”ì¶œ
            
        Returns:
            dict: ì „ì²´ ì²˜ë¦¬ ê²°ê³¼
        """
        start_time = datetime.now()
        mode_text = "ì „ë‚  ë°ì´í„°" if daily_only else "ì›”ê°„ ë°ì´í„°"
        
        logger.info("=" * 60)
        logger.info(f"ğŸš€ ì„±ì˜¤ ì¬ê³ í˜„í™© {mode_text} ì¶”ì¶œ ì‹œì‘")
        logger.info("=" * 60)
        
        # ë‚ ì§œ ì •ë³´ ì¶œë ¥
        year, month_name, date_info = self.get_target_date_info(target_date)
        logger.info(f"ğŸ“… ì²˜ë¦¬ ëŒ€ìƒ: {date_info.strftime('%Y-%m-%d')} ({year}ë…„ {month_name})")
        logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {os.path.abspath(self.output_base_dir)}")
        logger.info(f"ğŸ”§ ì¶”ì¶œ ëª¨ë“œ: {mode_text}")
        
        results = {
            'start_time': start_time,
            'target_date': date_info,
            'daily_only': daily_only,
            'sheets_processed': [],
            'success_count': 0,
            'total_count': len(self.target_sheets),
            'errors': []
        }
        
        # ê° ì‹œíŠ¸ ì²˜ë¦¬
        all_inventory_changes = []
        
        for sheet_name in self.target_sheets:
            try:
                result = self.extract_and_save_sheet(sheet_name, target_date, daily_only)
                results['sheets_processed'].append(result)
                
                if result['success']:
                    results['success_count'] += 1
                    # ì¬ê³  ë³€í™” ë°ì´í„° ìˆ˜ì§‘ (í†µí•© JSONìš©)
                    if daily_only and result.get('inventory_changes'):
                        all_inventory_changes.extend(result['inventory_changes'])
                else:
                    results['errors'].append(f"{sheet_name}: {result['error']}")
                    
            except Exception as e:
                error_msg = f"{sheet_name}: ì˜ˆì™¸ ë°œìƒ - {str(e)}"
                results['errors'].append(error_msg)
                logger.error(f"âŒ {error_msg}")
        
        # í†µí•© JSON ì €ì¥ (daily_onlyì´ê³  ë³€í™”ê°€ ìˆëŠ” ê²½ìš°)
        unified_json_path = None
        if daily_only and all_inventory_changes:
            unified_json_path = self.save_unified_inventory_changes_json(all_inventory_changes, target_date)
        
        results['unified_json_path'] = unified_json_path
        results['total_inventory_changes'] = len(all_inventory_changes)
        
        # ì™„ë£Œ ë³´ê³ 
        end_time = datetime.now()
        duration = end_time - start_time
        results['end_time'] = end_time
        results['duration'] = duration
        
        logger.info("-" * 60)
        logger.info(f"ğŸ“Š {mode_text} ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:")
        logger.info(f"  â€¢ ì„±ê³µ: {results['success_count']}/{results['total_count']} ì‹œíŠ¸")
        logger.info(f"  â€¢ ì†Œìš”ì‹œê°„: {duration.total_seconds():.2f}ì´ˆ")
        
        if results['errors']:
            logger.warning("âš ï¸ ì˜¤ë¥˜ ë°œìƒ:")
            for error in results['errors']:
                logger.warning(f"  â€¢ {error}")
        
        # ì„±ê³µí•œ íŒŒì¼ë“¤ ëª©ë¡
        successful_files = [r['file_path'] for r in results['sheets_processed'] if r['success']]
        
        if successful_files:
            logger.info("ğŸ’¾ ì €ì¥ëœ CSV íŒŒì¼ë“¤:")
            for file_path in successful_files:
                logger.info(f"  â€¢ {file_path}")
        
        # í†µí•© JSON íŒŒì¼ ì •ë³´
        if results.get('unified_json_path'):
            logger.info("ğŸ“„ í†µí•© JSON íŒŒì¼:")
            logger.info(f"  â€¢ {results['unified_json_path']}")
            logger.info(f"ğŸ“ˆ ì´ ì¬ê³  ë³€í™” ê¸°ë¡: {results['total_inventory_changes']}ê±´")
        
        logger.info("=" * 60)
        logger.info(f"ğŸ ì„±ì˜¤ ì¬ê³ í˜„í™© {mode_text} ì¶”ì¶œ ì™„ë£Œ")
        logger.info("=" * 60)
        
        return results


def main():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    # ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹±
    parser = argparse.ArgumentParser(description='ì„±ì˜¤ ì¬ê³ í˜„í™© ë°ì´í„° ìŠ¤ì¼€ì¤„ëŸ¬')
    parser.add_argument('--daily-only', action='store_true', 
                       help='ì „ë‚  ë°ì´í„°ë§Œ ì¶”ì¶œ (ê¸°ë³¸: ì „ì²´ ì›”ê°„ ë°ì´í„°)')
    parser.add_argument('--date', type=str, 
                       help='ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, ê¸°ë³¸: ì–´ì œ)')
    
    args = parser.parse_args()
    
    try:
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        scheduler = SungohInventoryScheduler()
        
        # ëŒ€ìƒ ë‚ ì§œ íŒŒì‹±
        target_date = None
        if args.date:
            try:
                target_date = datetime.strptime(args.date, '%Y-%m-%d')
                logger.info(f"ì‚¬ìš©ì ì§€ì • ë‚ ì§œ: {args.date}")
            except ValueError:
                logger.error(f"ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {args.date} (YYYY-MM-DD í˜•ì‹ ì‚¬ìš©)")
                return 3
        
        # ì¶”ì¶œ ëª¨ë“œ ê²°ì •
        daily_only = args.daily_only
        mode_text = "ì „ë‚  ë°ì´í„°ë§Œ" if daily_only else "ì „ì²´ ì›”ê°„ ë°ì´í„°"
        logger.info(f"ì¶”ì¶œ ëª¨ë“œ: {mode_text}")
        
        # ì¼ì¼ ì¶”ì¶œ ì‹¤í–‰
        results = scheduler.run_daily_extraction(target_date, daily_only)
        
        # ì„±ê³µ ì—¬ë¶€ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ ê²°ì •
        if results['success_count'] == results['total_count']:
            logger.info("âœ… ëª¨ë“  ì‹œíŠ¸ ì²˜ë¦¬ ì„±ê³µ")
            return 0
        elif results['success_count'] > 0:
            logger.warning("âš ï¸ ì¼ë¶€ ì‹œíŠ¸ ì²˜ë¦¬ ì„±ê³µ")
            return 1
        else:
            logger.error("âŒ ëª¨ë“  ì‹œíŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨")
            return 2
            
    except Exception as e:
        logger.error(f"ğŸ’¥ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        return 3


if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ì‹œ
    exit_code = main()
    sys.exit(exit_code)
